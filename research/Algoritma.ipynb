{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1n2PsMNu/S0GFnQzRsRwc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from scipy.signal import butter, lfilter\n","from sklearn.metrics import silhouette_score\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import classification_report,confusion_matrix\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import os\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import Adam\n","from sklearn import preprocessing\n","from keras.utils.np_utils import to_categorical\n","from sklearn.preprocessing import scale,StandardScaler,MinMaxScaler\n","from sklearn.decomposition import PCA, KernelPCA\n","from sklearn.manifold import TSNE\n","import tensorflow as tf\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import re\n","import os \n","import scipy\n","import math\n","import keras\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import keras\n","from scipy.stats import entropy\n","from sklearn.decomposition import PCA\n","from scipy.optimize import curve_fit\n","from scipy import signal\n","from pydrive.auth import GoogleAuth\n","from google.colab import drive\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pywt\n","drive.mount('/content/gdrive')"],"metadata":{"id":"IRWb3dgcMEaP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_data():\n","  "],"metadata":{"id":"JgzaLavnnMbh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def write_data():\n","  "],"metadata":{"id":"QkBbdo_XnPij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bandpass(x):\n","  # Cut-off frequency of the filter (in Hz)\n","  lowcut = 60\n","  highcut = 200\n","\n","  # Sampling rate of the data (in Hz)\n","  fs = 1000\n","\n","  # Filter order\n","  order = 2\n","\n","  # Design the band-pass Butterworth filter\n","  nyquist = 0.5 * fs\n","  low = lowcut / nyquist\n","  high = highcut / nyquist\n","  b, a = butter(order, [low, high], btype='band', analog=False)\n","\n","  # Apply the filter to the data\n","  y = lfilter(b, a, x)\n","\n","  return y"],"metadata":{"id":"OKYA6mNEMBL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def wavelet(sinyal):\n","  temp = pywt.WaveletPacket(data=sinyal, wavelet='db1', mode='symmetric')\n","  x = [node.path for node in temp.get_level(3, 'natural')]\n","  energy = [np.sum((temp[i].data)**2) for i in x]\n","\n","  return energy"],"metadata":{"id":"qkUIgr9qM6cj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_shannon_entropy(signal):\n","    return -np.nansum(signal**2 * np.log(signal**2))\n","\n","def wavelet_entropy(sinyal):\n","  temp = pywt.WaveletPacket(data=sinyal, wavelet='db1', mode='symmetric')\n","  x = [node.path for node in temp.get_level(3, 'natural')]\n","    \n","  entropy_ = [compute_shannon_entropy(temp[i].data) for i in x]\n","\n","  return entropy_"],"metadata":{"id":"cj7lYFcfM-RU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Class (belum direvisi)"],"metadata":{"id":"yKzQtfvPOrT1"}},{"cell_type":"code","source":["class preprocessing:\n","  def __init(self):\n","    self.filter=bandpass()\n","    self.wavelet_energy=wavelet_energy\n","    self.wavelet_entropy=wavelet_entropy\n","\n","  def bandpass(data):\n","    lowcut = 60\n","    highcut = 200\n","    fs = 1000\n","    order = 2\n","\n","    nyquist = 0.5 * fs\n","    low = lowcut / nyquist\n","    high = highcut / nyquist\n","    b, a = butter(order, [low, high], btype='band', analog=False)\n","    y = lfilter(b, a, data)\n","\n","    return y \n","\n","  def wavelet_energy(data):\n","    temp = pywt.WaveletPacket(data=data, wavelet='db1', mode='symmetric')\n","    x = [node.path for node in temp.get_level(3, 'natural')]\n","    energy = [np.sum((temp[i].data)**2) for i in x]\n","\n","    return energy\n","\n","  def compute_shannon_entropy(signal):\n","      return -np.nansum(signal**2 * np.log(signal**2))\n","\n","  def wavelet_entropy(data):\n","    temp = pywt.WaveletPacket(data=data, wavelet='db1', mode='symmetric')\n","    x = [node.path for node in temp.get_level(3, 'natural')]\n","      \n","    entropy_ = [compute_shannon_entropy(temp[i].data) for i in x]\n","\n","    return entropy_\n","\n","  def forward(data):\n","    "],"metadata":{"id":"dQC17golNiYE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Agent"],"metadata":{"id":"fOF_il1sOvf9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zo72IH3X4g4a"},"outputs":[],"source":["def prediction_agent():\n","  "]},{"cell_type":"code","source":["from torch.clusters import KMeans"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"Rxc6d6lIxH5m","executionInfo":{"status":"error","timestamp":1674530062730,"user_tz":-420,"elapsed":4903,"user":{"displayName":"Muhammad Ridlo","userId":"03432606588682739634"}},"outputId":"5639bc3e-b666-400e-968c-2a9fbc146b21"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f9c9b40d7541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclusters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.clusters'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def best_cluster():\n","  "],"metadata":{"id":"1IjIm3jnmgQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clustering():\n","  "],"metadata":{"id":"1l0KMO9vmext"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_cluster():\n","  "],"metadata":{"id":"H4tCKNldmovw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_agent():\n","  "],"metadata":{"id":"o2MSEQAfnyAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def retrain():\n","  #best n cluster\n","\n","  #clustering\n","\n","  \n","  #evaluate new clusters"],"metadata":{"id":"wWRH7IYQmdYg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","  "],"metadata":{"id":"Ha_94Un2nFBj"},"execution_count":null,"outputs":[]}]}